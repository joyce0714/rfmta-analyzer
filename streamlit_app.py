import streamlit as st
import pandas as pd
from datetime import datetime
import gspread
from google.oauth2.service_account import Credentials
import numpy as np
import traceback
import json
from io import BytesIO
import hashlib
import os

# å®‰å…¨é…ç½®
ALLOWED_USERS = ["user1@company.com", "user2@company.com"]  # å…è¨±çš„ä½¿ç”¨è€…æ¸…å–®
SESSION_TIMEOUT = 3600  # 1å°æ™‚å¾Œè‡ªå‹•ç™»å‡º

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="RFMTA å®¢æˆ¶åˆ†æå·¥å…· (å®‰å…¨ç‰ˆ)",
    page_icon="ğŸ”",
    layout="wide"
)

def check_authentication():
    """æª¢æŸ¥ä½¿ç”¨è€…èªè­‰"""
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    
    if not st.session_state.authenticated:
        st.title("ğŸ” ä½¿ç”¨è€…èªè­‰")
        
        # å¾ secrets è®€å–å¯†ç¢¼
        try:
            correct_password = st.secrets["security"]["admin_password"]
        except:
            correct_password = "your_secure_password_here"  # å‚™ç”¨å¯†ç¢¼
        
        password = st.text_input("è«‹è¼¸å…¥å­˜å–å¯†ç¢¼", type="password")
        
        if st.button("ç™»å…¥"):
            if password == correct_password:
                st.session_state.authenticated = True
                st.session_state.login_time = datetime.now()
                st.rerun()
            else:
                st.error("å¯†ç¢¼éŒ¯èª¤")
        
        st.info("è«‹è¯ç¹«ç®¡ç†å“¡ç²å–å­˜å–å¯†ç¢¼")
        return False
    
    # æª¢æŸ¥ session æ˜¯å¦éæœŸ
    if 'login_time' in st.session_state:
        elapsed = (datetime.now() - st.session_state.login_time).seconds
        if elapsed > SESSION_TIMEOUT:
            st.session_state.authenticated = False
            st.error("Session å·²éæœŸï¼Œè«‹é‡æ–°ç™»å…¥")
            st.rerun()
    
    return True

def sanitize_input(text):
    """æ¸…ç†ä½¿ç”¨è€…è¼¸å…¥"""
    if not text:
        return ""
    # ç§»é™¤æ½›åœ¨çš„æƒ¡æ„å­—ç¬¦
    import re
    return re.sub(r'[<>"\']', '', str(text))

class SecureRFMTAAnalyzer:
    def __init__(self):
        self.combined_data = None
        self.rfmt_result = None
        self.r_bins = None
        self.f_bins = None
        self.m_bins = None
        self.t_bins = None
        self.a_bins = None
        self.r_bounds = None
        self.f_bounds = None
        self.m_bounds = None
        self.t_bounds = None
        self.a_bounds = None
        self.frequency_by_sheet = None
        
    def create_google_sheet_output(self, export_df, sheet_title="RFMTA_Analysis"):
        """å°‡çµæœè¼¸å‡ºåˆ°æ–°çš„ Google Sheet"""
        try:
            # ä½¿ç”¨ Streamlit secrets ä¸­çš„æ†‘è­‰ï¼ˆæ›´å®‰å…¨ï¼‰
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            
            # å‰µå»ºæ–°çš„å·¥ä½œè¡¨ï¼Œæ·»åŠ æ™‚é–“æˆ³é¿å…é‡è¤‡
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            sheet_name = f"{sheet_title}_{timestamp}"
            
            # å‰µå»ºæ–°çš„ Google Sheet
            spreadsheet = client.create(sheet_name)
            worksheet = spreadsheet.sheet1
            
            # è¨­å®šå·¥ä½œè¡¨æ¬Šé™ï¼ˆå¯ç·¨è¼¯ä½†éœ€è¦é€£çµï¼‰
            spreadsheet.share(None, perm_type='anyone', role='writer')
            
            # æº–å‚™è³‡æ–™ï¼ˆè½‰æ›ç‚ºå­—ç¬¦ä¸²é¿å…æ ¼å¼å•é¡Œï¼‰
            data_to_write = []
            
            # æ¨™é¡Œè¡Œ
            headers = list(export_df.columns)
            data_to_write.append(headers)
            
            # è³‡æ–™è¡Œ
            for _, row in export_df.iterrows():
                row_data = []
                for col in headers:
                    value = row[col]
                    if pd.isna(value):
                        row_data.append("")
                    elif isinstance(value, (int, float)):
                        row_data.append(str(value))
                    else:
                        row_data.append(str(value))
                data_to_write.append(row_data)
            
            # ä¸€æ¬¡æ€§å¯«å…¥æ‰€æœ‰è³‡æ–™ï¼ˆæé«˜æ•ˆç‡ï¼‰
            worksheet.update(data_to_write)
            
            # æ ¼å¼åŒ–æ¨™é¡Œè¡Œ
            worksheet.format("1:1", {
                "backgroundColor": {"red": 0.2, "green": 0.6, "blue": 0.9},
                "textFormat": {"bold": True, "foregroundColor": {"red": 1, "green": 1, "blue": 1}}
            })
            
            # è‡ªå‹•èª¿æ•´æ¬„å¯¬
            worksheet.columns_auto_resize(0, len(headers)-1)
            
            return spreadsheet.url, sheet_name
            
        except Exception as e:
            error_msg = str(e)
            if "storage quota" in error_msg or "quota" in error_msg:
                st.error("âš ï¸ Google Drive å„²å­˜ç©ºé–“å·²æ»¿ï¼")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("""
                    **ğŸ’¡ ç«‹å³è§£æ±ºæ–¹æ¡ˆï¼š**
                    1. é¸æ“‡ "æ›´æ–°å›ºå®šå·¥ä½œè¡¨" æ¨¡å¼
                    2. ä½¿ç”¨ç¾æœ‰å·¥ä½œè¡¨åç¨±
                    3. é€™æ¨£ä¸æœƒå ç”¨æ–°ç©ºé–“
                    """)
                
                with col2:
                    st.markdown("""
                    **ğŸ› ï¸ é•·æœŸè§£æ±ºæ–¹æ¡ˆï¼š**
                    1. åœ¨å·¦å´é»æ“Š "ğŸ“Š æª¢æŸ¥å„²å­˜ç©ºé–“"
                    2. ç„¶å¾Œé»æ“Š "ğŸ§¹ æ¸…ç†èˆŠå·¥ä½œè¡¨"
                    3. æˆ–ä½¿ç”¨ "ğŸš¨ ç·Šæ€¥æ¸…ç†"
                    """)
            else:
                st.error(f"å‰µå»º Google Sheet æ™‚ç™¼ç”ŸéŒ¯èª¤: {error_msg}")
            
            return None, None
    
    @staticmethod
    def create_bins_and_labels(series, n_bins=4):
        """å››åˆ†ä½åˆ†ç´šå‡½æ•¸"""
        min_val, max_val = series.min(), series.max()
        
        if min_val == max_val:
            bins = [min_val - 0.1, min_val + 0.1]
            labels = [1]
        else:
            quartiles = np.percentile(series.dropna(), np.linspace(0, 100, n_bins + 1))
            bins = np.unique(quartiles)
            
            if len(bins) < 4:
                bins = np.linspace(min_val, max_val + 1, n_bins + 1)
            
            labels = list(range(1, len(bins)))
        
        bins = np.unique(bins)
        print(f"âœ… æœ€çµ‚ä½¿ç”¨çš„ bins for {series.name}: {bins}")
        return bins, labels, pd.Series(bins)
    
    def load_google_sheets_secure(self, sheet_names):
        """ä½¿ç”¨é è¨­æ†‘è­‰å®‰å…¨è¼‰å…¥ Google Sheets"""
        try:
            # ä½¿ç”¨ Streamlit secrets ä¸­çš„æ†‘è­‰
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            
            self.data = []
            total_rows = 0
            
            for sheet_name in sheet_names:
                # æ¸…ç†è¼¸å…¥
                sheet_name = sanitize_input(sheet_name)
                
                try:
                    sheet = client.open(sheet_name.strip()).sheet1
                    all_values = sheet.get_all_values()
                    
                    if not all_values:
                        st.warning(f"è­¦å‘Š: {sheet_name} æ˜¯ç©ºçš„æˆ–ç„¡æ³•è®€å–")
                        continue
                    
                    headers = all_values[0]
                    records = [dict(zip(headers, row)) for row in all_values[1:]]
                    df = pd.DataFrame(records)
                    df['SheetSource'] = sheet_name
                    df['OriginalRow'] = range(2, len(df) + 2)
                    
                    self.data.append(df)
                    total_rows += len(df)
                    st.success(f"å·²è¼‰å…¥ {len(df)} ç­†è³‡æ–™å¾ {sheet_name}")
                    
                except Exception as e:
                    st.error(f"è™•ç† {sheet_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            
            if not self.data:
                raise ValueError("æ²’æœ‰è³‡æ–™å¯ä»¥å¾ä»»ä½•å·¥ä½œè¡¨è¼‰å…¥")
            
            self.combined_data = pd.concat(self.data, ignore_index=True)
            
            # ç¯©é¸æœ‰æ•ˆæ•¸æ“š
            self.combined_data = self.combined_data[
                (self.combined_data['Email'].notna()) & 
                (self.combined_data['Email'] != '') & 
                (self.combined_data['ä»˜æ¬¾ç‹€æ…‹'] == 'å·²ä»˜æ¬¾') &
                (pd.to_numeric(self.combined_data['å¯¦éš›ä»˜æ¬¾é‡‘é¡'], errors='coerce') > 0)
            ]
            
            # å°‡ Email è½‰æ›ç‚ºå°å¯«
            self.combined_data['Email'] = self.combined_data['Email'].str.lower()
            
            # è§£ææ—¥æœŸ
            self.combined_data['è¨‚å–®æ™‚é–“'] = pd.to_datetime(
                self.combined_data['è¨‚å–®æ™‚é–“'], 
                errors='coerce'
            )
            
            st.success(f"è³‡æ–™è¼‰å…¥å®Œæˆï¼ç¸½å…± {len(self.combined_data)} ç­†æœ‰æ•ˆè¨˜éŒ„")
            
            return True
            
        except Exception as e:
            st.error(f"è¼‰å…¥è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return False
    
    def analyze_rfmta(self):
        """åŸ·è¡Œ RFMTA åˆ†æ"""
        try:
            if self.combined_data is None:
                st.error("è«‹å…ˆè¼‰å…¥è³‡æ–™")
                return False
            
            st.info("é–‹å§‹ RFMTA åˆ†æ...")
            
            now = datetime.now().date()
            email_col = 'Email'
            order_date_col = 'è¨‚å–®æ™‚é–“'
            total_amount_col = 'å¯¦éš›ä»˜æ¬¾é‡‘é¡'
            name_col = 'å§“å'
            
            # ç¢ºä¿é‡‘é¡æ¬„ä½è¢«æ­£ç¢ºè§£æç‚ºæ•¸å€¼
            self.combined_data[total_amount_col] = pd.to_numeric(
                self.combined_data[total_amount_col], 
                errors='coerce'
            ).fillna(0)
            
            # è¨ºæ–·æ—¥æœŸè§£æå•é¡Œ
            date_na_count = self.combined_data[order_date_col].isna().sum()
            if date_na_count > 0:
                st.warning(f"è­¦å‘Šï¼šæœ‰ {date_na_count} ç­†è¨‚å–®æ™‚é–“ç„¡æ³•è§£æ")
            
            # è¨ˆç®— Fï¼ˆè·¨ä½œå“åƒèˆ‡æ¬¡æ•¸ï¼‰
            frequency_by_sheet = self.combined_data.groupby(['Email', 'SheetSource']).size().reset_index(name='sheet_frequency')
            frequency_by_sheet['sheet_frequency'] = 1
            total_frequency = frequency_by_sheet.groupby('Email')['sheet_frequency'].sum().reset_index()
            
            # è¨ˆç®— Tï¼ˆç¸½åƒèˆ‡æ¬¡æ•¸ï¼‰
            total_times = self.combined_data.groupby('Email').size().reset_index(name='total_times')
            
            # è¨ˆç®— Mï¼ˆç¸½é‡‘é¡ï¼‰
            total_monetary = self.combined_data.groupby(email_col)[total_amount_col].sum().reset_index()
            
            # é¸æ“‡æœ€ä½³å§“å
            latest_orders = self.combined_data.sort_values(order_date_col).groupby('Email').last().reset_index()
            latest_orders['has_participant'] = latest_orders[name_col].str.contains('åƒåŠ è€…', na=False)
            
            name_selection = []
            for email, group in latest_orders.groupby('Email'):
                non_participant_names = group.loc[~group['has_participant'], name_col]
                if not non_participant_names.empty:
                    name_selection.append((email, non_participant_names.iloc[0]))
                else:
                    name_selection.append((email, group[name_col].iloc[0]))
            
            name_selection_df = pd.DataFrame(name_selection, columns=['Email', 'preferred_name'])
            
            # åˆå§‹åŒ– RFMT DataFrame
            rfmt = pd.DataFrame()
            
            # è¨ˆç®— Recency
            rfmt['Recency'] = self.combined_data.groupby(email_col)[order_date_col].max().apply(
                lambda x: (now - pd.to_datetime(x).date()).days if pd.notnull(x) else None
            )
            
            # R åˆ†å±¤
            rfmt['R'], self.r_bins = pd.qcut(
                rfmt['Recency'],
                q=4,
                labels=False,
                retbins=True,
                duplicates='drop'
            )
            
            num_labels = len(np.unique(rfmt['R'].dropna()))
            rfmt['R'] = num_labels - rfmt['R']
            rfmt['R'] = rfmt['R'].fillna(-1).astype(int)
            
            # æª¢æŸ¥ç„¡æ•ˆ R å€¼
            r_neg1_count = (rfmt['R'] == -1).sum()
            if r_neg1_count > 0:
                st.warning(f"è­¦å‘Šï¼šæœ‰ {r_neg1_count} ä½å®¢æˆ¶å› è¨‚å–®æ™‚é–“è§£æå¤±æ•—è€Œè¢«æ¨™è¨˜ç‚º R=-1")
            
            # è¨ˆç®—å…¶ä»–æŒ‡æ¨™
            rfmt['Frequency'] = total_frequency.set_index('Email')['sheet_frequency']
            rfmt['Monetary'] = total_monetary.set_index('Email')[total_amount_col]
            rfmt['Times'] = total_times.set_index('Email')['total_times']
            rfmt['Average'] = rfmt['Monetary'] / rfmt['Times']
            rfmt['Name'] = name_selection_df.set_index('Email')['preferred_name']

            # ============ ä¿®æ”¹çš„ F è¨ˆç®—é‚è¼¯é–‹å§‹ ============
            # F çš„å›ºå®šåˆ†ç´šï¼š1ä½œå“=F1, 2ä½œå“=F2, 3ä½œå“=F3, 4+ä½œå“=F4
            def calculate_f_score(frequency):
                """
                æ ¹æ“šåƒåŠ ä½œå“æ•¸è¨ˆç®— F åˆ†æ•¸
                F1 = åƒåŠ  1 å€‹ä½œå“
                F2 = åƒåŠ  2 å€‹ä½œå“  
                F3 = åƒåŠ  3 å€‹ä½œå“
                F4 = åƒåŠ  4 å€‹æˆ–ä»¥ä¸Šä½œå“
                """
                if frequency == 1:
                    return 1
                elif frequency == 2:
                    return 2
                elif frequency == 3:
                    return 3
                elif frequency >= 4:
                    return 4
                else:
                    return 1  # é è¨­å€¼ï¼Œç†è«–ä¸Šä¸æœƒç™¼ç”Ÿ

            # æ‡‰ç”¨æ–°çš„ F è¨ˆç®—é‚è¼¯
            rfmt['F'] = rfmt['Frequency'].apply(calculate_f_score)

            # è¨­å®š F çš„é‚Šç•Œå€¼ï¼ˆç”¨æ–¼è¼¸å‡ºèªªæ˜ï¼‰
            self.f_bins = [0.5, 1.5, 2.5, 3.5, float('inf')]  # åˆ†ç•Œé»
            self.f_bounds = pd.Series(self.f_bins)  # ä¿æŒèˆ‡åŸç‰ˆæ ¼å¼ä¸€è‡´
            # ============ ä¿®æ”¹çš„ F è¨ˆç®—é‚è¼¯çµæŸ ============

            # M, T, A å››åˆ†ä½åˆ†å±¤ï¼ˆä¿æŒåŸä¾†çš„é‚è¼¯ï¼‰
            self.m_bins, m_labels, self.m_bounds = self.create_bins_and_labels(rfmt['Monetary'])
            self.t_bins, t_labels, self.t_bounds = self.create_bins_and_labels(rfmt['Times'])
            self.a_bins, a_labels, self.a_bounds = self.create_bins_and_labels(rfmt['Average'])

            # æ³¨æ„ï¼šé€™è£¡ä¸å†è¨ˆç®— Fï¼Œå› ç‚ºå·²ç¶“åœ¨ä¸Šé¢ç”¨å›ºå®šåˆ†ç´šäº†
            rfmt['M'] = pd.cut(rfmt['Monetary'], bins=self.m_bins, labels=m_labels, include_lowest=True)
            rfmt['T'] = pd.cut(rfmt['Times'], bins=self.t_bins, labels=t_labels, include_lowest=True)
            rfmt['A'] = pd.cut(rfmt['Average'], bins=self.a_bins, labels=a_labels, include_lowest=True)
            
            # RFMTA çµ„åˆ
            rfmt['RFMTA_Score'] = (rfmt['R'].astype(str) + rfmt['F'].astype(str) + 
                                 rfmt['M'].astype(str) + rfmt['T'].astype(str) + 
                                 rfmt['A'].astype(str))
            
            self.rfmt_result = rfmt
            self.frequency_by_sheet = frequency_by_sheet
            
            st.success("RFMTA åˆ†æå®Œæˆï¼")
            return True
            
        except Exception as e:
            st.error(f"åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return False
    
    def get_export_data(self):
        """æº–å‚™åŒ¯å‡ºè³‡æ–™"""
        if self.rfmt_result is None:
            return None
        
        try:
            # é‡æ–°ç²å–å®Œæ•´è³‡æ–™é€²è¡ŒåŒ¯å‡º
            # ç”±æ–¼æˆ‘å€‘ä¿ç•™äº† frequency_by_sheetï¼Œå¯ä»¥é‡å»ºéœ€è¦çš„è³‡è¨Š
            
            # åŸºæœ¬çš„ RFMTA çµæœ
            export_df = self.rfmt_result.copy()
            export_df = export_df.reset_index()
            
            # é‡æ–°å‘½å Name ç‚º å§“å
            if 'Name' in export_df.columns:
                export_df = export_df.rename(columns={'Name': 'å§“å'})
            
            # åŸºæœ¬è¼¸å‡ºæ¬„ä½
            base_columns = ['Email', 'å§“å', 'Recency', 'Frequency', 'Monetary', 'Times', 'Average',
                           'R', 'F', 'M', 'T', 'A', 'RFMTA_Score']
            
            # ç¢ºä¿æ‰€æœ‰åŸºæœ¬æ¬„ä½éƒ½å­˜åœ¨
            for col in base_columns:
                if col not in export_df.columns:
                    export_df[col] = ""
            
            # ä½œå“åƒèˆ‡æ¬¡æ•¸æ¬„ä½ï¼ˆå¾åŸå§‹è³‡æ–™é‡å»ºï¼‰
            if hasattr(self, 'combined_data') and self.combined_data is not None:
                sheet_columns = sorted(set(self.combined_data['SheetSource'].unique()))
                
                # å¡«å……æ¯å€‹ä½œå“çš„åƒèˆ‡æ¬¡æ•¸
                for sheet in sheet_columns:
                    participation_counts = self.combined_data[
                        self.combined_data['SheetSource'] == sheet
                    ].groupby('Email').size()
                    export_df[sheet] = export_df['Email'].map(participation_counts).fillna(0).astype(int)
            else:
                sheet_columns = []
            
            # æº–å‚™é‚Šç•Œèªªæ˜æ¬„ä½
            boundary_columns = []
            
            # ============ R çš„é‚Šç•Œèªªæ˜ ============
            if hasattr(self, 'r_bins') and self.r_bins is not None:
                for i in range(len(self.r_bins)-1):
                    idx = len(self.r_bins) - 2 - i  # åè½‰ç´¢å¼•
                    next_idx = idx + 1
                    export_df[f'R{i+1}_Boundary'] = f"R{i+1}: {self.r_bins[idx]:.0f} to less than {self.r_bins[next_idx]:.0f} days"
                    boundary_columns.append(f'R{i+1}_Boundary')
            
            # ============ F çš„é‚Šç•Œèªªæ˜ï¼ˆä¿®æ”¹å¾Œçš„å›ºå®šåˆ†ç´šï¼‰============
            f_boundary_descriptions = [
                "F1: participated in 1 different work",
                "F2: participated in 2 different works", 
                "F3: participated in 3 different works",
                "F4: participated in 4 or more different works"
            ]
            
            for i, description in enumerate(f_boundary_descriptions):
                export_df[f'F{i+1}_Boundary'] = description
                boundary_columns.append(f'F{i+1}_Boundary')
            
            # ============ M çš„é‚Šç•Œèªªæ˜ ============
            if hasattr(self, 'm_bins') and self.m_bins is not None:
                for i in range(len(self.m_bins)-1):
                    if i == len(self.m_bins)-2:
                        export_df[f'M{i+1}_Boundary'] = f"M{i+1}: ${self.m_bins[i]:.0f} and above"
                    else:
                        next_value = self.m_bins[i+1]
                        export_df[f'M{i+1}_Boundary'] = f"M{i+1}: ${self.m_bins[i]:.0f} to less than ${next_value:.0f}"
                    boundary_columns.append(f'M{i+1}_Boundary')
            
            # ============ T çš„é‚Šç•Œèªªæ˜ ============
            if hasattr(self, 't_bins') and self.t_bins is not None:
                for i in range(len(self.t_bins)-1):
                    if i == len(self.t_bins)-2:
                        export_df[f'T{i+1}_Boundary'] = f"T{i+1}: {int(self.t_bins[i])} times or more in total"
                    else:
                        current_value = int(self.t_bins[i]) + 1 if i > 0 else int(self.t_bins[i])
                        next_value = int(self.t_bins[i+1])
                        export_df[f'T{i+1}_Boundary'] = f"T{i+1}: {current_value} to {next_value} times in total"
                    boundary_columns.append(f'T{i+1}_Boundary')
            
            # ============ A çš„é‚Šç•Œèªªæ˜ ============
            if hasattr(self, 'a_bins') and self.a_bins is not None:
                for i in range(len(self.a_bins)-1):
                    if i == len(self.a_bins)-2:
                        export_df[f'A{i+1}_Boundary'] = f"A{i+1}: ${self.a_bins[i]:.0f} and above per participation"
                    else:
                        next_value = self.a_bins[i+1]
                        export_df[f'A{i+1}_Boundary'] = f"A{i+1}: ${self.a_bins[i]:.0f} to less than ${next_value:.0f} per participation"
                    boundary_columns.append(f'A{i+1}_Boundary')
            
            # çµ„åˆæœ€çµ‚çš„æ¬„ä½é †åº
            columns_to_export = base_columns + sheet_columns + boundary_columns
            
            # ç¢ºä¿æ‰€æœ‰æŒ‡å®šçš„åˆ—éƒ½å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨å‰‡å¡«å……ç‚ºç©º
            for col in columns_to_export:
                if col not in export_df.columns:
                    export_df[col] = ""
            
            return export_df[columns_to_export].copy()
            
        except Exception as e:
            st.error(f"æº–å‚™åŒ¯å‡ºè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return None

    def create_or_update_google_sheet(self, export_df, sheet_title="RFMTA_Dashboard"):
        """æ›´æ–°å›ºå®šçš„ Google Sheetï¼Œé©åˆ Looker Studio é€£æ¥"""
        try:
            # ä½¿ç”¨ Streamlit secrets ä¸­çš„æ†‘è­‰
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            
            # å›ºå®šçš„å·¥ä½œè¡¨åç¨±
            fixed_sheet_name = sheet_title
            
            try:
                # å˜—è©¦é–‹å•Ÿç¾æœ‰çš„å·¥ä½œè¡¨
                spreadsheet = client.open(fixed_sheet_name)
                st.info(f"âœ… æ‰¾åˆ°ç¾æœ‰å·¥ä½œè¡¨ï¼š{fixed_sheet_name}")
                
            except gspread.SpreadsheetNotFound:
                # å¦‚æœå·¥ä½œè¡¨ä¸å­˜åœ¨ï¼Œå‰µå»ºæ–°çš„
                spreadsheet = client.create(fixed_sheet_name)
                spreadsheet.share(None, perm_type='anyone', role='writer')
                st.success(f"ğŸ†• å‰µå»ºæ–°å·¥ä½œè¡¨ï¼š{fixed_sheet_name}")
            
            # é¸æ“‡ç¬¬ä¸€å€‹å·¥ä½œè¡¨
            worksheet = spreadsheet.sheet1
            
            # æ¸…ç©ºç¾æœ‰æ•¸æ“š
            worksheet.clear()
            st.info("ğŸ§¹ æ¸…ç©ºèˆŠæ•¸æ“š...")
            
            # æº–å‚™æ–°æ•¸æ“š
            data_to_write = []
            
            # æ·»åŠ åˆ†ææ™‚é–“æˆ³è¨˜åˆ°ç¬¬ä¸€è¡Œ
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            data_to_write.append([f"æœ€å¾Œæ›´æ–°æ™‚é–“: {timestamp}"])
            data_to_write.append([])  # ç©ºè¡Œ
            
            # æ¨™é¡Œè¡Œ
            headers = list(export_df.columns)
            data_to_write.append(headers)
            
            # è³‡æ–™è¡Œ
            for _, row in export_df.iterrows():
                row_data = []
                for col in headers:
                    value = row[col]
                    if pd.isna(value):
                        row_data.append("")
                    elif isinstance(value, (int, float)):
                        row_data.append(value)  # ä¿æŒæ•¸å€¼æ ¼å¼
                    else:
                        row_data.append(str(value))
                data_to_write.append(row_data)
            
            # ä¸€æ¬¡æ€§å¯«å…¥æ‰€æœ‰è³‡æ–™
            worksheet.update(data_to_write)
            st.success("ğŸ“Š æ•¸æ“šæ›´æ–°å®Œæˆï¼")
            
            # æ ¼å¼åŒ–æ¨™é¡Œè¡Œï¼ˆç¬¬3è¡Œæ˜¯çœŸæ­£çš„æ¨™é¡Œï¼‰
            worksheet.format("3:3", {
                "backgroundColor": {"red": 0.2, "green": 0.6, "blue": 0.9},
                "textFormat": {"bold": True, "foregroundColor": {"red": 1, "green": 1, "blue": 1}}
            })
            
            # æ ¼å¼åŒ–æ™‚é–“æˆ³è¨˜è¡Œ
            worksheet.format("1:1", {
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9},
                "textFormat": {"bold": True, "fontSize": 10}
            })
            
            # è‡ªå‹•èª¿æ•´æ¬„å¯¬
            worksheet.columns_auto_resize(0, len(headers)-1)
            
            return spreadsheet.url, fixed_sheet_name
            
        except Exception as e:
            st.error(f"æ›´æ–° Google Sheet æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return None, None
    
    def create_or_update_google_sheet_with_history(self, export_df, sheet_title="RFMTA_Dashboard"):
        """æ›´æ–°å›ºå®š Google Sheetï¼ŒåŒæ™‚ä¿ç•™æ­·å²è¨˜éŒ„"""
        try:
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            fixed_sheet_name = sheet_title
            
            try:
                spreadsheet = client.open(fixed_sheet_name)
                st.info(f"âœ… æ‰¾åˆ°ç¾æœ‰å·¥ä½œè¡¨ï¼š{fixed_sheet_name}")
            except gspread.SpreadsheetNotFound:
                spreadsheet = client.create(fixed_sheet_name)
                spreadsheet.share(None, perm_type='anyone', role='writer')
                st.success(f"ğŸ†• å‰µå»ºæ–°å·¥ä½œè¡¨ï¼š{fixed_sheet_name}")
            
            # ç¢ºä¿æœ‰éœ€è¦çš„å·¥ä½œè¡¨åˆ†é 
            worksheet_names = [ws.title for ws in spreadsheet.worksheets()]
            
            # ä¸»è¦æ•¸æ“šå·¥ä½œè¡¨ï¼ˆä¾› Looker Studio ä½¿ç”¨ï¼‰
            if "æœ€æ–°æ•¸æ“š" not in worksheet_names:
                main_worksheet = spreadsheet.add_worksheet(title="æœ€æ–°æ•¸æ“š", rows=1000, cols=50)
            else:
                main_worksheet = spreadsheet.worksheet("æœ€æ–°æ•¸æ“š")
            
            # æ­·å²è¨˜éŒ„å·¥ä½œè¡¨
            if "æ­·å²è¨˜éŒ„" not in worksheet_names:
                history_worksheet = spreadsheet.add_worksheet(title="æ­·å²è¨˜éŒ„", rows=10000, cols=10)
            else:
                history_worksheet = spreadsheet.worksheet("æ­·å²è¨˜éŒ„")
            
            # === æ›´æ–°ä¸»è¦æ•¸æ“šå·¥ä½œè¡¨ ===
            main_worksheet.clear()
            
            # æº–å‚™ä¸»è¦æ•¸æ“š
            data_to_write = []
            headers = list(export_df.columns)
            data_to_write.append(headers)
            
            for _, row in export_df.iterrows():
                row_data = []
                for col in headers:
                    value = row[col]
                    if pd.isna(value):
                        row_data.append("")
                    elif isinstance(value, (int, float)):
                        row_data.append(value)
                    else:
                        row_data.append(str(value))
                data_to_write.append(row_data)
            
            main_worksheet.update(data_to_write)
            
            # æ ¼å¼åŒ–ä¸»è¦æ•¸æ“šå·¥ä½œè¡¨
            main_worksheet.format("1:1", {
                "backgroundColor": {"red": 0.2, "green": 0.6, "blue": 0.9},
                "textFormat": {"bold": True, "foregroundColor": {"red": 1, "green": 1, "blue": 1}}
            })
            
            # === æ›´æ–°æ­·å²è¨˜éŒ„ ===
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            customer_count = len(export_df)
            total_revenue = export_df['Monetary'].sum() if 'Monetary' in export_df.columns else 0
            
            # ç²å–ç¾æœ‰æ­·å²è¨˜éŒ„
            try:
                existing_history = history_worksheet.get_all_records()
            except:
                existing_history = []
                # æ·»åŠ æ¨™é¡Œè¡Œ
                history_worksheet.update("A1:E1", [["åˆ†ææ™‚é–“", "å®¢æˆ¶æ•¸é‡", "ç¸½æ”¶å…¥", "å¹³å‡å®¢å–®åƒ¹", "å‚™è¨»"]])
            
            # æ·»åŠ æ–°è¨˜éŒ„
            avg_revenue = total_revenue / customer_count if customer_count > 0 else 0
            new_record = [timestamp, customer_count, f"${total_revenue:.0f}", f"${avg_revenue:.0f}", "è‡ªå‹•åˆ†æ"]
            
            # æ‰¾åˆ°ä¸‹ä¸€å€‹ç©ºè¡Œ
            next_row = len(existing_history) + 2  # +2 å› ç‚ºæœ‰æ¨™é¡Œè¡Œä¸”å¾1é–‹å§‹è¨ˆæ•¸
            history_worksheet.update(f"A{next_row}:E{next_row}", [new_record])
            
            st.success("ğŸ“Š ä¸»è¦æ•¸æ“šå’Œæ­·å²è¨˜éŒ„éƒ½å·²æ›´æ–°ï¼")
            
            return spreadsheet.url, fixed_sheet_name
            
        except Exception as e:
            st.error(f"æ›´æ–° Google Sheet æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return None, None

    def check_all_drive_files(self):
        """æª¢æŸ¥æ‰€æœ‰ Google Drive æª”æ¡ˆçš„è©³ç´°è³‡è¨Š"""
        try:
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            
            # å–å¾—æ‰€æœ‰æª”æ¡ˆæ¸…å–®
            all_files = client.list_spreadsheet_files()
            
            st.write(f"**ğŸ“‹ æ‰€æœ‰æª”æ¡ˆæ¸…å–®ï¼ˆå…± {len(all_files)} å€‹ï¼‰ï¼š**")
            
            total_size_info = []
            
            for i, file_info in enumerate(all_files, 1):
                name = file_info.get('name', 'æœªçŸ¥æª”æ¡ˆ')
                file_id = file_info.get('id', '')
                created_time = file_info.get('createdTime', 'æœªçŸ¥æ™‚é–“')
                
                # é¡¯ç¤ºæª”æ¡ˆè³‡è¨Š
                st.write(f"""
                **æª”æ¡ˆ {i}ï¼š**
                - ğŸ“„ åç¨±ï¼š`{name}`
                - ğŸ• å»ºç«‹æ™‚é–“ï¼š{created_time}
                - ğŸ†” IDï¼š`{file_id[:20]}...`
                """)
                
                total_size_info.append({
                    'name': name,
                    'id': file_id,
                    'created_time': created_time
                })
            
            return total_size_info
            
        except Exception as e:
            st.error(f"æª¢æŸ¥æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return []

    def cleanup_all_sheets(self, exclude_keywords=None):
        """æ¸…ç†æ‰€æœ‰å·¥ä½œè¡¨ï¼ˆè¬¹æ…ä½¿ç”¨ï¼‰"""
        if exclude_keywords is None:
            exclude_keywords = ['RFMTA_Dashboard', 'important', 'keep', 'é‡è¦']
        
        try:
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            all_files = client.list_spreadsheet_files()
            
            files_to_delete = []
            files_to_keep = []
            
            for file_info in all_files:
                name = file_info.get('name', '')
                should_keep = False
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«è¦ä¿ç•™çš„é—œéµå­—
                for keyword in exclude_keywords:
                    if keyword.lower() in name.lower():
                        should_keep = True
                        break
                
                if should_keep:
                    files_to_keep.append(name)
                else:
                    files_to_delete.append(file_info)
            
            st.write(f"**ğŸ“‹ å°‡ä¿ç•™çš„æª”æ¡ˆï¼ˆ{len(files_to_keep)} å€‹ï¼‰ï¼š**")
            for name in files_to_keep:
                st.write(f"- âœ… {name}")
            
            st.write(f"**ğŸ—‘ï¸ å°‡åˆªé™¤çš„æª”æ¡ˆï¼ˆ{len(files_to_delete)} å€‹ï¼‰ï¼š**")
            for file_info in files_to_delete:
                st.write(f"- âŒ {file_info.get('name', 'æœªçŸ¥')}")
            
            return len(files_to_delete), files_to_delete
            
        except Exception as e:
            st.error(f"æª¢æŸ¥æ¸…ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return 0, []

    def emergency_cleanup(self, confirm_delete=False):
        """ç·Šæ€¥æ¸…ç†ï¼ˆåˆªé™¤æ‰€æœ‰éé‡è¦æª”æ¡ˆï¼‰"""
        try:
            if not confirm_delete:
                st.warning("âš ï¸ é€™æ˜¯ç·Šæ€¥æ¸…ç†åŠŸèƒ½ï¼Œæœƒåˆªé™¤å¤§éƒ¨åˆ†æª”æ¡ˆï¼")
                return 0
            
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            all_files = client.list_spreadsheet_files()
            
            # ä¿ç•™æ¸…å–®ï¼ˆé‡è¦æª”æ¡ˆä¸åˆªé™¤ï¼‰
            keep_keywords = ['RFMTA_Dashboard', 'Dashboard', 'important', 'keep', 'é‡è¦']
            
            deleted_count = 0
            
            for file_info in all_files:
                name = file_info.get('name', '')
                file_id = file_info.get('id', '')
                
                # æª¢æŸ¥æ˜¯å¦è¦ä¿ç•™
                should_keep = False
                for keyword in keep_keywords:
                    if keyword.lower() in name.lower():
                        should_keep = True
                        break
                
                if not should_keep:
                    try:
                        client.del_spreadsheet(file_id)
                        deleted_count += 1
                        st.info(f"ğŸ—‘ï¸ å·²åˆªé™¤ï¼š{name}")
                    except Exception as e:
                        st.warning(f"âŒ ç„¡æ³•åˆªé™¤ {name}: {str(e)}")
            
            st.success(f"ğŸ‰ ç·Šæ€¥æ¸…ç†å®Œæˆï¼åˆªé™¤äº† {deleted_count} å€‹æª”æ¡ˆ")
            return deleted_count
            
        except Exception as e:
            st.error(f"ç·Šæ€¥æ¸…ç†å¤±æ•—: {str(e)}")
            return 0

    def cleanup_old_sheets(self, keep_latest=5):
        """æ¸…ç†èˆŠçš„ RFMTA åˆ†æå·¥ä½œè¡¨ï¼Œä¿ç•™æœ€æ–°çš„å¹¾å€‹"""
        try:
            # ä½¿ç”¨ Streamlit secrets ä¸­çš„æ†‘è­‰
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            
            # å–å¾—æ‰€æœ‰å·¥ä½œè¡¨
            all_sheets = client.list_spreadsheet_files()
            
            # ç¯©é¸å‡º RFMTA ç›¸é—œçš„å·¥ä½œè¡¨ï¼ˆå¸¶æ™‚é–“æˆ³è¨˜çš„ï¼‰
            rfmta_sheets = []
            for sheet in all_sheets:
                name = sheet.get('name', '')
                # æ‰¾å‡ºå¸¶æ™‚é–“æˆ³è¨˜çš„å·¥ä½œè¡¨ï¼Œä½†ä¿ç•™å›ºå®šåç¨±çš„å·¥ä½œè¡¨
                if 'RFMTA' in name and ('_202' in name or '_201' in name):  # å¸¶å¹´ä»½æ™‚é–“æˆ³è¨˜çš„
                    rfmta_sheets.append({
                        'id': sheet['id'],
                        'name': name,
                        'createdTime': sheet.get('createdTime', '')
                    })
            
            st.info(f"æ‰¾åˆ° {len(rfmta_sheets)} å€‹å¸¶æ™‚é–“æˆ³è¨˜çš„ RFMTA å·¥ä½œè¡¨")
            
            # æŒ‰å‰µå»ºæ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            rfmta_sheets.sort(key=lambda x: x['createdTime'], reverse=True)
            
            # åˆªé™¤å¤šé¤˜çš„èˆŠå·¥ä½œè¡¨
            deleted_count = 0
            if len(rfmta_sheets) > keep_latest:
                sheets_to_delete = rfmta_sheets[keep_latest:]
                
                for sheet in sheets_to_delete:
                    try:
                        # åˆªé™¤å·¥ä½œè¡¨
                        spreadsheet = client.open_by_key(sheet['id'])
                        client.del_spreadsheet(sheet['id'])
                        deleted_count += 1
                        st.info(f"âœ… å·²åˆªé™¤: {sheet['name']}")
                    except Exception as e:
                        st.warning(f"âŒ ç„¡æ³•åˆªé™¤ {sheet['name']}: {str(e)}")
            
            if deleted_count > 0:
                st.success(f"ğŸ‰ æ¸…ç†å®Œæˆï¼å·²åˆªé™¤ {deleted_count} å€‹èˆŠå·¥ä½œè¡¨ï¼Œä¿ç•™æœ€æ–° {keep_latest} å€‹")
            else:
                st.info("âœ¨ æ²’æœ‰éœ€è¦æ¸…ç†çš„èˆŠå·¥ä½œè¡¨")
                
            return deleted_count
            
        except Exception as e:
            st.error(f"æ¸…ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return 0

    def check_drive_usage(self):
        """æª¢æŸ¥ Google Drive ä½¿ç”¨æƒ…æ³"""
        try:
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            
            # å–å¾—æ‰€æœ‰æª”æ¡ˆæ¸…å–®
            all_files = client.list_spreadsheet_files()
            
            total_files = len(all_files)
            rfmta_files = sum(1 for f in all_files if 'RFMTA' in f.get('name', ''))
            rfmta_timestamped = sum(1 for f in all_files 
                                  if 'RFMTA' in f.get('name', '') and ('_202' in f.get('name', '') or '_201' in f.get('name', '')))
            
            st.info(f"""
            **ğŸ“Š Google Drive ä½¿ç”¨æƒ…æ³ï¼š**
            - ğŸ“ ç¸½æª”æ¡ˆæ•¸ï¼š{total_files}
            - ğŸ“‹ RFMTA ç›¸é—œæª”æ¡ˆï¼š{rfmta_files}
            - ğŸ• å¸¶æ™‚é–“æˆ³è¨˜çš„æª”æ¡ˆï¼š{rfmta_timestamped}
            """)
            
            # é¡¯ç¤ºæœ€è¿‘çš„æª”æ¡ˆ
            rfmta_recent = [f for f in all_files if 'RFMTA' in f.get('name', '')][:5]
            if rfmta_recent:
                st.write("**ğŸ“‹ æœ€è¿‘çš„ RFMTA æª”æ¡ˆï¼š**")
                for f in rfmta_recent:
                    st.write(f"- {f.get('name', 'æœªçŸ¥')}")
            
            return total_files, rfmta_files, rfmta_timestamped
            
        except Exception as e:
            st.warning(f"ç„¡æ³•æª¢æŸ¥ Drive ä½¿ç”¨æƒ…æ³: {str(e)}")
            return 0, 0, 0


# Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»é«”
def main():
    # æª¢æŸ¥èªè­‰
    if not check_authentication():
        return
    
    st.title("ğŸ” RFMTA å®¢æˆ¶åˆ†æå·¥å…· (å®‰å…¨ç‰ˆ)")
    st.markdown("---")
    
    # é¡¯ç¤ºç™»å…¥è³‡è¨Š
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button("ğŸšª ç™»å‡º"):
            st.session_state.authenticated = False
            st.rerun()
    
    # åˆå§‹åŒ–åˆ†æå™¨
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = SecureRFMTAAnalyzer()
    
    # å´é‚Šæ¬„ - è³‡æ–™è¼‰å…¥
    st.sidebar.header("ğŸ”§ è¨­å®š")
    
    # Google Sheets åç¨±è¼¸å…¥
    st.sidebar.subheader("è¼¸å…¥ Google Sheets åç¨±")
    sheet_names_input = st.sidebar.text_area(
        "è«‹è¼¸å…¥å·¥ä½œè¡¨åç¨±ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰",
        height=100,
        placeholder="ä¾‹å¦‚ï¼š\n2024å¹´æ´»å‹•å ±åè¡¨\n2023å¹´æœƒå“¡åå–®"
    )
    
    # è¼‰å…¥è³‡æ–™æŒ‰éˆ•
    if st.sidebar.button("ğŸ”„ è¼‰å…¥è³‡æ–™", type="primary"):
        if sheet_names_input:
            sheet_names = [sanitize_input(name.strip()) for name in sheet_names_input.split('\n') if name.strip()]
            
            with st.spinner("è¼‰å…¥è³‡æ–™ä¸­..."):
                success = st.session_state.analyzer.load_google_sheets_secure(sheet_names)
                if success:
                    st.rerun()
        else:
            st.sidebar.error("è«‹è¼¸å…¥å·¥ä½œè¡¨åç¨±")
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ—‚ï¸ Drive ç®¡ç†")
    
    # åŸºæœ¬æª¢æŸ¥
    if st.sidebar.button("ğŸ“Š æª¢æŸ¥å„²å­˜ç©ºé–“"):
        with st.spinner("æª¢æŸ¥ä¸­..."):
            total_files, rfmta_files, timestamped_files = st.session_state.analyzer.check_drive_usage()
    
    # è©³ç´°æª¢æŸ¥
    if st.sidebar.button("ğŸ” æŸ¥çœ‹æ‰€æœ‰æª”æ¡ˆ"):
        with st.spinner("æª¢æŸ¥æ‰€æœ‰æª”æ¡ˆä¸­..."):
            all_files_info = st.session_state.analyzer.check_all_drive_files()
    
    # åˆ†ææ¸…ç†é¸é …
    if st.sidebar.button("ğŸ“Š åˆ†ææ¸…ç†é¸é …"):
        with st.spinner("åˆ†æä¸­..."):
            count_to_delete, files_to_delete = st.session_state.analyzer.cleanup_all_sheets()
            if count_to_delete > 0:
                st.sidebar.info(f"å¯ä»¥æ¸…ç† {count_to_delete} å€‹æª”æ¡ˆ")
    
    # åŸæœ¬çš„ RFMTA æ¸…ç†ï¼ˆä¿ç•™ï¼‰
    st.sidebar.write("**RFMTA æª”æ¡ˆæ¸…ç†ï¼š**")
    keep_count = st.sidebar.selectbox("ä¿ç•™æœ€æ–°å¹¾å€‹æª”æ¡ˆ", [3, 5, 10, 15], index=1)
    
    if st.sidebar.button("ğŸ§¹ æ¸…ç† RFMTA æª”æ¡ˆ"):
        with st.spinner("æ¸…ç†ä¸­..."):
            deleted_count = st.session_state.analyzer.cleanup_old_sheets(keep_latest=keep_count)
            if deleted_count > 0:
                st.sidebar.success(f"âœ… å·²æ¸…ç† {deleted_count} å€‹ RFMTA æª”æ¡ˆ")
    
    # ç·Šæ€¥æ¸…ç†é¸é …
    st.sidebar.markdown("---")
    st.sidebar.write("**âš ï¸ ç·Šæ€¥æ¸…ç†é¸é …ï¼š**")
    emergency_confirm = st.sidebar.checkbox("æˆ‘äº†è§£é¢¨éšªï¼Œç¢ºèªç·Šæ€¥æ¸…ç†")
    
    if st.sidebar.button("ğŸš¨ åŸ·è¡Œç·Šæ€¥æ¸…ç†", type="secondary") and emergency_confirm:
        with st.spinner("ç·Šæ€¥æ¸…ç†ä¸­ï¼Œè«‹ç¨å€™..."):
            deleted_count = st.session_state.analyzer.emergency_cleanup(confirm_delete=True)
            if deleted_count > 0:
                st.sidebar.success(f"âœ… ç·Šæ€¥æ¸…ç†å®Œæˆï¼æ¸…ç†äº† {deleted_count} å€‹æª”æ¡ˆ")
                st.sidebar.info("ğŸ’¡ ç¾åœ¨å¯ä»¥å‰µå»ºæ–°å·¥ä½œè¡¨äº†ï¼")
    
    # ä½¿ç”¨èªªæ˜
    st.sidebar.info("""
    ğŸ’¡ **å»ºè­°æ­¥é©Ÿï¼š**
    1. å…ˆé»ã€ŒğŸ” æŸ¥çœ‹æ‰€æœ‰æª”æ¡ˆã€
    2. å†é»ã€ŒğŸ“Š åˆ†ææ¸…ç†é¸é …ã€  
    3. ç¢ºèªå¾ŒåŸ·è¡Œç·Šæ€¥æ¸…ç†
    """)
    
    # ä¸»è¦å…§å®¹å€åŸŸ
    if st.session_state.analyzer.combined_data is not None:
        # è³‡æ–™æ¦‚è¦½ï¼ˆä¸é¡¯ç¤ºæ•æ„Ÿè³‡è¨Šï¼‰
        st.subheader("ğŸ“‹ è³‡æ–™æ¦‚è¦½")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç¸½è¨˜éŒ„æ•¸", len(st.session_state.analyzer.combined_data))
        
        with col2:
            unique_customers = st.session_state.analyzer.combined_data['Email'].nunique()
            st.metric("å”¯ä¸€å®¢æˆ¶æ•¸", unique_customers)
        
        with col3:
            unique_sheets = st.session_state.analyzer.combined_data['SheetSource'].nunique()
            st.metric("ä½œå“æ•¸é‡", unique_sheets)
        
        # é¡¯ç¤ºä½œå“åƒèˆ‡çµ±è¨ˆ
        if st.checkbox("é¡¯ç¤ºä½œå“åƒèˆ‡çµ±è¨ˆ"):
            sheet_counts = st.session_state.analyzer.combined_data['SheetSource'].value_counts()
            st.write("**å„ä½œå“åƒèˆ‡çµ±è¨ˆ:**")
            for sheet, count in sheet_counts.items():
                st.write(f"- {sheet}: {count} ç­†è¨˜éŒ„")
        
        # åˆ†ææŒ‰éˆ•
        if st.button("ğŸ” åŸ·è¡Œ RFMTA åˆ†æ", type="primary"):
            with st.spinner("åˆ†æä¸­..."):
                success = st.session_state.analyzer.analyze_rfmta()
                if success:
                    st.rerun()
    
    # é¡¯ç¤ºåˆ†æçµæœ
    if st.session_state.analyzer.rfmt_result is not None:
        # æ·»åŠ ç©ºé–“ç‹€æ…‹æª¢æŸ¥
        with st.expander("ğŸ—‚ï¸ å„²å­˜ç©ºé–“ç‹€æ…‹"):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ğŸ“Š å¿«é€Ÿæª¢æŸ¥"):
                    total, rfmta, timestamped = st.session_state.analyzer.check_drive_usage()
            
            with col2:
                if st.button("ğŸ§¹ å¿«é€Ÿæ¸…ç†"):
                    deleted = st.session_state.analyzer.cleanup_old_sheets(keep_latest=5)
                    if deleted > 0:
                        st.success(f"æ¸…ç†äº† {deleted} å€‹æª”æ¡ˆ")
            
            with col3:
                st.info("ğŸ’¡ å»ºè­°å®šæœŸæ¸…ç†ä»¥ç¯€çœç©ºé–“")
        st.subheader("ğŸ“ˆ RFMTA åˆ†æçµæœ")
        
        # åˆ†æçµæœçµ±è¨ˆ
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**å„æŒ‡æ¨™åˆ†å¸ƒ**")
            for metric in ['R', 'F', 'M', 'T', 'A']:
                dist = st.session_state.analyzer.rfmt_result[metric].value_counts().sort_index()
                st.write(f"{metric}: {dict(dist)}")
        
        with col2:
            st.write("**RFMTA Score ç¯„ä¾‹**")
            sample_scores = st.session_state.analyzer.rfmt_result['RFMTA_Score'].head(5)
            for score in sample_scores.values:
                st.write(f"Score: {score}")
        
        # é¡¯ç¤ºå®Œæ•´çµæœè¡¨æ ¼
        if st.checkbox("é¡¯ç¤ºå®Œæ•´åˆ†æçµæœ"):
            # ä¸é¡¯ç¤ºæ•æ„Ÿçš„ Email å’Œå§“åè³‡è¨Š
            display_columns = ['Recency', 'Frequency', 'Monetary', 'Times', 'Average', 'R', 'F', 'M', 'T', 'A', 'RFMTA_Score']
            available_columns = [col for col in display_columns if col in st.session_state.analyzer.rfmt_result.columns]
            st.dataframe(st.session_state.analyzer.rfmt_result[available_columns])
        
        # å‰µå»º/æ›´æ–° Google Sheet è¼¸å‡º
        st.subheader("ğŸ“Š æ›´æ–° RFMTA Dashboard")
        
        # é¸æ“‡æ›´æ–°æ¨¡å¼
        update_mode = st.radio(
            "é¸æ“‡æ›´æ–°æ¨¡å¼",
            options=["æ›´æ–°å›ºå®šå·¥ä½œè¡¨ï¼ˆæ¨è–¦çµ¦ Looker Studioï¼‰", "å‰µå»ºæ–°å·¥ä½œè¡¨ï¼ˆå«æ™‚é–“æˆ³è¨˜ï¼‰"],
            help="å›ºå®šå·¥ä½œè¡¨æ¨¡å¼é©åˆé€£æ¥ Looker Studioï¼Œæ•¸æ“šæœƒè‡ªå‹•æ›´æ–°"
        )
        
        # å·¥ä½œè¡¨åç¨±è¨­å®š
        if update_mode == "æ›´æ–°å›ºå®šå·¥ä½œè¡¨ï¼ˆæ¨è–¦çµ¦ Looker Studioï¼‰":
            sheet_name = st.text_input("å›ºå®šå·¥ä½œè¡¨åç¨±", value="RFMTA_Dashboard", 
                                      help="é€™å€‹åç¨±å°‡å›ºå®šä½¿ç”¨ï¼Œæ¯æ¬¡åˆ†ææœƒæ›´æ–°ç›¸åŒå·¥ä½œè¡¨")
            button_text = "ğŸ”„ æ›´æ–° Dashboard"
            button_help = "æ›´æ–°å›ºå®šå·¥ä½œè¡¨ä¸­çš„æ•¸æ“šï¼Œé©åˆ Looker Studio è‡ªå‹•åŒæ­¥"
        else:
            sheet_name = st.text_input("å·¥ä½œè¡¨åç¨±", value="RFMTA_Analysis")
            button_text = "ğŸ“ å‰µå»ºæ–°å·¥ä½œè¡¨"
            button_help = "å‰µå»ºåŒ…å«æ™‚é–“æˆ³è¨˜çš„æ–°å·¥ä½œè¡¨"
        
        # åŸ·è¡ŒæŒ‰éˆ•
        if st.button(button_text, type="primary", help=button_help):
            with st.spinner("æ­£åœ¨å‰µå»º Google Sheet..."):
                export_data = st.session_state.analyzer.get_export_data()
                
                if export_data is not None:
                    if update_mode == "æ›´æ–°å›ºå®šå·¥ä½œè¡¨ï¼ˆæ¨è–¦çµ¦ Looker Studioï¼‰":
                        # ä½¿ç”¨å›ºå®šå·¥ä½œè¡¨æ›´æ–°æ¨¡å¼
                        sheet_url, final_sheet_name = st.session_state.analyzer.create_or_update_google_sheet_with_history(
                            export_data, 
                            sanitize_input(sheet_name)
                        )
                        
                        if sheet_url:
                            st.success("âœ… Dashboard æ›´æ–°æˆåŠŸï¼")
                            st.markdown(f"**ğŸ“‹ å·¥ä½œè¡¨åç¨±:** {final_sheet_name}")
                            st.markdown(f"**ğŸ”— [é»æ“Šé–‹å•Ÿ RFMTA Dashboard]({sheet_url})**")
                            
                            # Looker Studio é€£æ¥æŒ‡å¼•
                            with st.expander("ğŸ“Š å¦‚ä½•é€£æ¥åˆ° Looker Studio"):
                                st.markdown(f"""
                                **æ­¥é©Ÿ 1:** å‰å¾€ [Looker Studio](https://lookerstudio.google.com/)
                                
                                **æ­¥é©Ÿ 2:** é»æ“Š "å»ºç«‹" â†’ "è³‡æ–™ä¾†æº"
                                
                                **æ­¥é©Ÿ 3:** é¸æ“‡ "Google è©¦ç®—è¡¨"
                                
                                **æ­¥é©Ÿ 4:** é¸æ“‡å·¥ä½œè¡¨ï¼š`{final_sheet_name}`
                                
                                **æ­¥é©Ÿ 5:** é¸æ“‡å·¥ä½œè¡¨åˆ†é ï¼š`æœ€æ–°æ•¸æ“š`
                                
                                **æ­¥é©Ÿ 6:** é»æ“Š "å»ºç«‹å ±è¡¨"
                                
                                ğŸ¯ **å¥½è™•:** æ¯æ¬¡ä½ æ›´æ–°åˆ†æï¼ŒLooker Studio æœƒè‡ªå‹•åŒæ­¥æœ€æ–°æ•¸æ“šï¼
                                """)
                            
                            # åˆ†äº«æŒ‡å¼•
                            st.info("""
                            **Dashboard ä½¿ç”¨èªªæ˜:**
                            - ğŸ“Š **æœ€æ–°æ•¸æ“š** åˆ†é ï¼šä¾› Looker Studio é€£æ¥ä½¿ç”¨
                            - ğŸ“ˆ **æ­·å²è¨˜éŒ„** åˆ†é ï¼šè¨˜éŒ„æ¯æ¬¡åˆ†æçš„æ‘˜è¦è³‡è¨Š
                            - ğŸ”„ æ¯æ¬¡åˆ†ææœƒè‡ªå‹•æ›´æ–°æ•¸æ“šï¼Œç„¡éœ€æ‰‹å‹•æ“ä½œ
                            """)
                            
                    else:
                        # ä½¿ç”¨åŸæœ¬çš„å‰µå»ºæ–°å·¥ä½œè¡¨æ¨¡å¼
                        sheet_url, final_sheet_name = st.session_state.analyzer.create_google_sheet_output(
                            export_data, 
                            sanitize_input(sheet_name)
                        )
                        
                        if sheet_url:
                            st.success("âœ… æ–°å·¥ä½œè¡¨å‰µå»ºæˆåŠŸï¼")
                            st.markdown(f"**ğŸ“‹ å·¥ä½œè¡¨åç¨±:** {final_sheet_name}")
                            st.markdown(f"**ğŸ”— [é»æ“Šé–‹å•Ÿ Google Sheet]({sheet_url})**")
                    
                    
                        
                        # é¡¯ç¤ºåŒ¯å‡ºæ¬„ä½èªªæ˜
                        with st.expander("ğŸ“‹ åŒ¯å‡ºæ¬„ä½èªªæ˜"):
                            st.markdown("""
                            **åŸºæœ¬æ¬„ä½:**
                            - Email, å§“å, Recency, Frequency, Monetary, Times, Average
                            - R, F, M, T, A, RFMTA_Score
                            
                            **ä½œå“åƒèˆ‡æ¬¡æ•¸:**
                            - å„ä½œå“çš„å€‹åˆ¥åƒèˆ‡æ¬¡æ•¸çµ±è¨ˆ
                            
                            **é‚Šç•Œèªªæ˜:**
                            - R1-R4_Boundary: æœ€è¿‘è³¼è²·æ™‚é–“åˆ†ç´šèªªæ˜
                            - F1-F4_Boundary: åƒèˆ‡ä½œå“æ•¸åˆ†ç´šèªªæ˜ï¼ˆå›ºå®šåˆ†ç´šï¼‰
                            - M1-M4_Boundary: æ¶ˆè²»é‡‘é¡åˆ†ç´šèªªæ˜
                            - T1-T4_Boundary: ç¸½åƒèˆ‡æ¬¡æ•¸åˆ†ç´šèªªæ˜
                            - A1-A4_Boundary: å¹³å‡æ¶ˆè²»åˆ†ç´šèªªæ˜
                            
                            **F åˆ†ç´šç‰¹è‰²ï¼ˆå·²ä¿®æ”¹ç‚ºå›ºå®šåˆ†ç´šï¼‰:**
                            - F1: åƒåŠ  1 å€‹ä½œå“
                            - F2: åƒåŠ  2 å€‹ä½œå“
                            - F3: åƒåŠ  3 å€‹ä½œå“
                            - F4: åƒåŠ  4 å€‹æˆ–ä»¥ä¸Šä½œå“
                            """)
    
    else:
        if st.session_state.analyzer.combined_data is None:
            st.info("ğŸ‘† è«‹å…ˆåœ¨å·¦å´è¼‰å…¥è³‡æ–™")
            
            # ä½¿ç”¨èªªæ˜
            st.subheader("ğŸ“– ä½¿ç”¨èªªæ˜")
            st.markdown("""
            **å®‰å…¨ç‰ˆæœ¬ç‰¹è‰²:**
            - ğŸ” éœ€è¦å¯†ç¢¼èªè­‰æ‰èƒ½ä½¿ç”¨
            - ğŸ”’ ä½¿ç”¨é è¨­çš„ Google API æ†‘è­‰ï¼Œç„¡éœ€ä¸Šå‚³æ•æ„Ÿæª”æ¡ˆ
            - ğŸ—‘ï¸ åˆ†æå®Œæˆå¾Œè‡ªå‹•æ¸…é™¤åŸå§‹è³‡æ–™
            - â±ï¸ Session æœƒåœ¨ 1 å°æ™‚å¾Œè‡ªå‹•éæœŸ
            - ğŸ“Š çµæœç›´æ¥è¼¸å‡ºç‚º Google Sheetï¼Œæ˜“æ–¼åˆ†äº«
            
            **ä½¿ç”¨æ­¥é©Ÿ:**
            1. åœ¨å·¦å´è¼¸å…¥è¦åˆ†æçš„ Google Sheets åç¨±
            2. é»æ“Šã€Œè¼‰å…¥è³‡æ–™ã€
            3. åŸ·è¡Œ RFMTA åˆ†æ
            4. å‰µå»ºçµæœ Google Sheet ä¸¦åˆ†äº«
            
            **RFMTA åˆ†æèªªæ˜:**
            - **R (Recency)**: æœ€è¿‘è³¼è²·æ™‚é–“ï¼ˆå››åˆ†ä½æ•¸åˆ†ç´šï¼‰
            - **F (Frequency)**: è·¨ä½œå“åƒèˆ‡æ¬¡æ•¸ï¼ˆå›ºå®šåˆ†ç´šï¼š1,2,3,4+å€‹ä½œå“ï¼‰
            - **M (Monetary)**: ç¸½æ¶ˆè²»é‡‘é¡ï¼ˆå››åˆ†ä½æ•¸åˆ†ç´šï¼‰
            - **T (Times)**: ç¸½åƒèˆ‡æ¬¡æ•¸ï¼ˆå››åˆ†ä½æ•¸åˆ†ç´šï¼‰
            - **A (Average)**: å¹³å‡æ¯æ¬¡æ¶ˆè²»é‡‘é¡ï¼ˆå››åˆ†ä½æ•¸åˆ†ç´šï¼‰
            """)

if __name__ == "__main__":
    main()
