import streamlit as st
import pandas as pd
from datetime import datetime
import gspread
from google.oauth2.service_account import Credentials
import numpy as np
import traceback
import json
from io import BytesIO
import hashlib
import os

# å®‰å…¨é…ç½®
ALLOWED_USERS = ["user1@company.com", "user2@company.com"]  # å…è¨±çš„ä½¿ç”¨è€…æ¸…å–®
SESSION_TIMEOUT = 3600  # 1å°æ™‚å¾Œè‡ªå‹•ç™»å‡º

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="RFMTA å®¢æˆ¶åˆ†æå·¥å…· (å®‰å…¨ç‰ˆ)",
    page_icon="ğŸ”",
    layout="wide"
)

def check_authentication():
    """æª¢æŸ¥ä½¿ç”¨è€…èªè­‰"""
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    
    if not st.session_state.authenticated:
        st.title("ğŸ” ä½¿ç”¨è€…èªè­‰")
        
        # å¾ secrets è®€å–å¯†ç¢¼
        try:
            correct_password = st.secrets["security"]["admin_password"]
        except:
            correct_password = "your_secure_password_here"  # å‚™ç”¨å¯†ç¢¼
        
        password = st.text_input("è«‹è¼¸å…¥å­˜å–å¯†ç¢¼", type="password")
        
        if st.button("ç™»å…¥"):
            if password == correct_password:
                st.session_state.authenticated = True
                st.session_state.login_time = datetime.now()
                st.rerun()
            else:
                st.error("å¯†ç¢¼éŒ¯èª¤")
        
        st.info("è«‹è¯ç¹«ç®¡ç†å“¡ç²å–å­˜å–å¯†ç¢¼")
        return False
    
    # æª¢æŸ¥ session æ˜¯å¦éæœŸ
    if 'login_time' in st.session_state:
        elapsed = (datetime.now() - st.session_state.login_time).seconds
        if elapsed > SESSION_TIMEOUT:
            st.session_state.authenticated = False
            st.error("Session å·²éæœŸï¼Œè«‹é‡æ–°ç™»å…¥")
            st.rerun()
    
    return True

def sanitize_input(text):
    """æ¸…ç†ä½¿ç”¨è€…è¼¸å…¥"""
    if not text:
        return ""
    # ç§»é™¤æ½›åœ¨çš„æƒ¡æ„å­—ç¬¦
    import re
    return re.sub(r'[<>"\']', '', str(text))

class SecureRFMTAAnalyzer:
    def __init__(self):
        self.combined_data = None
        self.rfmt_result = None
        self.r_bins = None
        self.f_bins = None
        self.m_bins = None
        self.t_bins = None
        self.a_bins = None
        self.r_bounds = None
        self.f_bounds = None
        self.m_bounds = None
        self.t_bounds = None
        self.a_bounds = None
        self.frequency_by_sheet = None
        
    def create_google_sheet_output(self, export_df, sheet_title="RFMTA_Analysis"):
        """å°‡çµæœè¼¸å‡ºåˆ°æ–°çš„ Google Sheet"""
        try:
            # ä½¿ç”¨ Streamlit secrets ä¸­çš„æ†‘è­‰ï¼ˆæ›´å®‰å…¨ï¼‰
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            
            # å‰µå»ºæ–°çš„å·¥ä½œè¡¨ï¼Œæ·»åŠ æ™‚é–“æˆ³é¿å…é‡è¤‡
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            sheet_name = f"{sheet_title}_{timestamp}"
            
            # å‰µå»ºæ–°çš„ Google Sheet
            spreadsheet = client.create(sheet_name)
            worksheet = spreadsheet.sheet1
            
            # è¨­å®šå·¥ä½œè¡¨æ¬Šé™ï¼ˆå¯ç·¨è¼¯ä½†éœ€è¦é€£çµï¼‰
            spreadsheet.share(None, perm_type='anyone', role='writer')
            
            # æº–å‚™è³‡æ–™ï¼ˆè½‰æ›ç‚ºå­—ç¬¦ä¸²é¿å…æ ¼å¼å•é¡Œï¼‰
            data_to_write = []
            
            # æ¨™é¡Œè¡Œ
            headers = list(export_df.columns)
            data_to_write.append(headers)
            
            # è³‡æ–™è¡Œ
            for _, row in export_df.iterrows():
                row_data = []
                for col in headers:
                    value = row[col]
                    if pd.isna(value):
                        row_data.append("")
                    elif isinstance(value, (int, float)):
                        row_data.append(str(value))
                    else:
                        row_data.append(str(value))
                data_to_write.append(row_data)
            
            # ä¸€æ¬¡æ€§å¯«å…¥æ‰€æœ‰è³‡æ–™ï¼ˆæé«˜æ•ˆç‡ï¼‰
            worksheet.update(data_to_write)
            
            # æ ¼å¼åŒ–æ¨™é¡Œè¡Œ
            worksheet.format("1:1", {
                "backgroundColor": {"red": 0.2, "green": 0.6, "blue": 0.9},
                "textFormat": {"bold": True, "foregroundColor": {"red": 1, "green": 1, "blue": 1}}
            })
            
            # è‡ªå‹•èª¿æ•´æ¬„å¯¬
            worksheet.columns_auto_resize(0, len(headers)-1)
            
            return spreadsheet.url, sheet_name
            
        except Exception as e:
            st.error(f"å‰µå»º Google Sheet æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return None, None
    
    @staticmethod
    def create_bins_and_labels(series, n_bins=4):
        """å››åˆ†ä½åˆ†ç´šå‡½æ•¸"""
        min_val, max_val = series.min(), series.max()
        
        if min_val == max_val:
            bins = [min_val - 0.1, min_val + 0.1]
            labels = [1]
        else:
            quartiles = np.percentile(series.dropna(), np.linspace(0, 100, n_bins + 1))
            bins = np.unique(quartiles)
            
            if len(bins) < 4:
                bins = np.linspace(min_val, max_val + 1, n_bins + 1)
            
            labels = list(range(1, len(bins)))
        
        bins = np.unique(bins)
        print(f"âœ… æœ€çµ‚ä½¿ç”¨çš„ bins for {series.name}: {bins}")
        return bins, labels, pd.Series(bins)
    
    def load_google_sheets_secure(self, sheet_names):
        """ä½¿ç”¨é è¨­æ†‘è­‰å®‰å…¨è¼‰å…¥ Google Sheets"""
        try:
            # ä½¿ç”¨ Streamlit secrets ä¸­çš„æ†‘è­‰
            credentials_dict = st.secrets["google_credentials"]
            credentials = Credentials.from_service_account_info(
                credentials_dict,
                scopes=['https://spreadsheets.google.com/feeds', 
                       'https://www.googleapis.com/auth/drive']
            )
            
            client = gspread.authorize(credentials)
            
            self.data = []
            total_rows = 0
            
            for sheet_name in sheet_names:
                # æ¸…ç†è¼¸å…¥
                sheet_name = sanitize_input(sheet_name)
                
                try:
                    sheet = client.open(sheet_name.strip()).sheet1
                    all_values = sheet.get_all_values()
                    
                    if not all_values:
                        st.warning(f"è­¦å‘Š: {sheet_name} æ˜¯ç©ºçš„æˆ–ç„¡æ³•è®€å–")
                        continue
                    
                    headers = all_values[0]
                    records = [dict(zip(headers, row)) for row in all_values[1:]]
                    df = pd.DataFrame(records)
                    df['SheetSource'] = sheet_name
                    df['OriginalRow'] = range(2, len(df) + 2)
                    
                    self.data.append(df)
                    total_rows += len(df)
                    st.success(f"å·²è¼‰å…¥ {len(df)} ç­†è³‡æ–™å¾ {sheet_name}")
                    
                except Exception as e:
                    st.error(f"è™•ç† {sheet_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            
            if not self.data:
                raise ValueError("æ²’æœ‰è³‡æ–™å¯ä»¥å¾ä»»ä½•å·¥ä½œè¡¨è¼‰å…¥")
            
            self.combined_data = pd.concat(self.data, ignore_index=True)
            
            # ç¯©é¸æœ‰æ•ˆæ•¸æ“š
            self.combined_data = self.combined_data[
                (self.combined_data['Email'].notna()) & 
                (self.combined_data['Email'] != '') & 
                (self.combined_data['ä»˜æ¬¾ç‹€æ…‹'] == 'å·²ä»˜æ¬¾') &
                (pd.to_numeric(self.combined_data['å¯¦éš›ä»˜æ¬¾é‡‘é¡'], errors='coerce') > 0)
            ]
            
            # å°‡ Email è½‰æ›ç‚ºå°å¯«
            self.combined_data['Email'] = self.combined_data['Email'].str.lower()
            
            # è§£ææ—¥æœŸ
            self.combined_data['è¨‚å–®æ™‚é–“'] = pd.to_datetime(
                self.combined_data['è¨‚å–®æ™‚é–“'], 
                errors='coerce'
            )
            
            st.success(f"è³‡æ–™è¼‰å…¥å®Œæˆï¼ç¸½å…± {len(self.combined_data)} ç­†æœ‰æ•ˆè¨˜éŒ„")
            
            return True
            
        except Exception as e:
            st.error(f"è¼‰å…¥è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return False
    
    def analyze_rfmta(self):
        """åŸ·è¡Œ RFMTA åˆ†æ"""
        try:
            if self.combined_data is None:
                st.error("è«‹å…ˆè¼‰å…¥è³‡æ–™")
                return False
            
            st.info("é–‹å§‹ RFMTA åˆ†æ...")
            
            now = datetime.now().date()
            email_col = 'Email'
            order_date_col = 'è¨‚å–®æ™‚é–“'
            total_amount_col = 'å¯¦éš›ä»˜æ¬¾é‡‘é¡'
            name_col = 'å§“å'
            
            # ç¢ºä¿é‡‘é¡æ¬„ä½è¢«æ­£ç¢ºè§£æç‚ºæ•¸å€¼
            self.combined_data[total_amount_col] = pd.to_numeric(
                self.combined_data[total_amount_col], 
                errors='coerce'
            ).fillna(0)
            
            # è¨ºæ–·æ—¥æœŸè§£æå•é¡Œ
            date_na_count = self.combined_data[order_date_col].isna().sum()
            if date_na_count > 0:
                st.warning(f"è­¦å‘Šï¼šæœ‰ {date_na_count} ç­†è¨‚å–®æ™‚é–“ç„¡æ³•è§£æ")
            
            # è¨ˆç®— Fï¼ˆè·¨ä½œå“åƒèˆ‡æ¬¡æ•¸ï¼‰
            frequency_by_sheet = self.combined_data.groupby(['Email', 'SheetSource']).size().reset_index(name='sheet_frequency')
            frequency_by_sheet['sheet_frequency'] = 1
            total_frequency = frequency_by_sheet.groupby('Email')['sheet_frequency'].sum().reset_index()
            
            # è¨ˆç®— Tï¼ˆç¸½åƒèˆ‡æ¬¡æ•¸ï¼‰
            total_times = self.combined_data.groupby('Email').size().reset_index(name='total_times')
            
            # è¨ˆç®— Mï¼ˆç¸½é‡‘é¡ï¼‰
            total_monetary = self.combined_data.groupby(email_col)[total_amount_col].sum().reset_index()
            
            # é¸æ“‡æœ€ä½³å§“å
            latest_orders = self.combined_data.sort_values(order_date_col).groupby('Email').last().reset_index()
            latest_orders['has_participant'] = latest_orders[name_col].str.contains('åƒåŠ è€…', na=False)
            
            name_selection = []
            for email, group in latest_orders.groupby('Email'):
                non_participant_names = group.loc[~group['has_participant'], name_col]
                if not non_participant_names.empty:
                    name_selection.append((email, non_participant_names.iloc[0]))
                else:
                    name_selection.append((email, group[name_col].iloc[0]))
            
            name_selection_df = pd.DataFrame(name_selection, columns=['Email', 'preferred_name'])
            
            # åˆå§‹åŒ– RFMT DataFrame
            rfmt = pd.DataFrame()
            
            # è¨ˆç®— Recency
            rfmt['Recency'] = self.combined_data.groupby(email_col)[order_date_col].max().apply(
                lambda x: (now - pd.to_datetime(x).date()).days if pd.notnull(x) else None
            )
            
            # R åˆ†å±¤
            rfmt['R'], self.r_bins = pd.qcut(
                rfmt['Recency'],
                q=4,
                labels=False,
                retbins=True,
                duplicates='drop'
            )
            
            num_labels = len(np.unique(rfmt['R'].dropna()))
            rfmt['R'] = num_labels - rfmt['R']
            rfmt['R'] = rfmt['R'].fillna(-1).astype(int)
            
            # æª¢æŸ¥ç„¡æ•ˆ R å€¼
            r_neg1_count = (rfmt['R'] == -1).sum()
            if r_neg1_count > 0:
                st.warning(f"è­¦å‘Šï¼šæœ‰ {r_neg1_count} ä½å®¢æˆ¶å› è¨‚å–®æ™‚é–“è§£æå¤±æ•—è€Œè¢«æ¨™è¨˜ç‚º R=-1")
            
            # è¨ˆç®—å…¶ä»–æŒ‡æ¨™
            rfmt['Frequency'] = total_frequency.set_index('Email')['sheet_frequency']
            rfmt['Monetary'] = total_monetary.set_index('Email')[total_amount_col]
            rfmt['Times'] = total_times.set_index('Email')['total_times']
            rfmt['Average'] = rfmt['Monetary'] / rfmt['Times']
            rfmt['Name'] = name_selection_df.set_index('Email')['preferred_name']

            # ============ ä¿®æ”¹çš„ F è¨ˆç®—é‚è¼¯é–‹å§‹ ============
            # F çš„å›ºå®šåˆ†ç´šï¼š1ä½œå“=F1, 2ä½œå“=F2, 3ä½œå“=F3, 4+ä½œå“=F4
            def calculate_f_score(frequency):
                """
                æ ¹æ“šåƒåŠ ä½œå“æ•¸è¨ˆç®— F åˆ†æ•¸
                F1 = åƒåŠ  1 å€‹ä½œå“
                F2 = åƒåŠ  2 å€‹ä½œå“  
                F3 = åƒåŠ  3 å€‹ä½œå“
                F4 = åƒåŠ  4 å€‹æˆ–ä»¥ä¸Šä½œå“
                """
                if frequency == 1:
                    return 1
                elif frequency == 2:
                    return 2
                elif frequency == 3:
                    return 3
                elif frequency >= 4:
                    return 4
                else:
                    return 1  # é è¨­å€¼ï¼Œç†è«–ä¸Šä¸æœƒç™¼ç”Ÿ

            # æ‡‰ç”¨æ–°çš„ F è¨ˆç®—é‚è¼¯
            rfmt['F'] = rfmt['Frequency'].apply(calculate_f_score)

            # è¨­å®š F çš„é‚Šç•Œå€¼ï¼ˆç”¨æ–¼è¼¸å‡ºèªªæ˜ï¼‰
            self.f_bins = [0.5, 1.5, 2.5, 3.5, float('inf')]  # åˆ†ç•Œé»
            self.f_bounds = pd.Series(self.f_bins)  # ä¿æŒèˆ‡åŸç‰ˆæ ¼å¼ä¸€è‡´
            # ============ ä¿®æ”¹çš„ F è¨ˆç®—é‚è¼¯çµæŸ ============

            # M, T, A å››åˆ†ä½åˆ†å±¤ï¼ˆä¿æŒåŸä¾†çš„é‚è¼¯ï¼‰
            self.m_bins, m_labels, self.m_bounds = self.create_bins_and_labels(rfmt['Monetary'])
            self.t_bins, t_labels, self.t_bounds = self.create_bins_and_labels(rfmt['Times'])
            self.a_bins, a_labels, self.a_bounds = self.create_bins_and_labels(rfmt['Average'])

            # æ³¨æ„ï¼šé€™è£¡ä¸å†è¨ˆç®— Fï¼Œå› ç‚ºå·²ç¶“åœ¨ä¸Šé¢ç”¨å›ºå®šåˆ†ç´šäº†
            rfmt['M'] = pd.cut(rfmt['Monetary'], bins=self.m_bins, labels=m_labels, include_lowest=True)
            rfmt['T'] = pd.cut(rfmt['Times'], bins=self.t_bins, labels=t_labels, include_lowest=True)
            rfmt['A'] = pd.cut(rfmt['Average'], bins=self.a_bins, labels=a_labels, include_lowest=True)
            
            # RFMTA çµ„åˆ
            rfmt['RFMTA_Score'] = (rfmt['R'].astype(str) + rfmt['F'].astype(str) + 
                                 rfmt['M'].astype(str) + rfmt['T'].astype(str) + 
                                 rfmt['A'].astype(str))
            
            self.rfmt_result = rfmt
            self.frequency_by_sheet = frequency_by_sheet
            
            st.success("RFMTA åˆ†æå®Œæˆï¼")
            return True
            
        except Exception as e:
            st.error(f"åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return False
    
    def get_export_data(self):
        """æº–å‚™åŒ¯å‡ºè³‡æ–™"""
        if self.rfmt_result is None:
            return None
        
        try:
            # é‡æ–°ç²å–å®Œæ•´è³‡æ–™é€²è¡ŒåŒ¯å‡º
            # ç”±æ–¼æˆ‘å€‘ä¿ç•™äº† frequency_by_sheetï¼Œå¯ä»¥é‡å»ºéœ€è¦çš„è³‡è¨Š
            
            # åŸºæœ¬çš„ RFMTA çµæœ
            export_df = self.rfmt_result.copy()
            export_df = export_df.reset_index()
            
            # é‡æ–°å‘½å Name ç‚º å§“å
            if 'Name' in export_df.columns:
                export_df = export_df.rename(columns={'Name': 'å§“å'})
            
            # åŸºæœ¬è¼¸å‡ºæ¬„ä½
            base_columns = ['Email', 'å§“å', 'Recency', 'Frequency', 'Monetary', 'Times', 'Average',
                           'R', 'F', 'M', 'T', 'A', 'RFMTA_Score']
            
            # ç¢ºä¿æ‰€æœ‰åŸºæœ¬æ¬„ä½éƒ½å­˜åœ¨
            for col in base_columns:
                if col not in export_df.columns:
                    export_df[col] = ""
            
            # ä½œå“åƒèˆ‡æ¬¡æ•¸æ¬„ä½ï¼ˆå¾åŸå§‹è³‡æ–™é‡å»ºï¼‰
            if hasattr(self, 'combined_data') and self.combined_data is not None:
                sheet_columns = sorted(set(self.combined_data['SheetSource'].unique()))
                
                # å¡«å……æ¯å€‹ä½œå“çš„åƒèˆ‡æ¬¡æ•¸
                for sheet in sheet_columns:
                    participation_counts = self.combined_data[
                        self.combined_data['SheetSource'] == sheet
                    ].groupby('Email').size()
                    export_df[sheet] = export_df['Email'].map(participation_counts).fillna(0).astype(int)
            else:
                sheet_columns = []
            
            # æº–å‚™é‚Šç•Œèªªæ˜æ¬„ä½
            boundary_columns = []
            
            # ============ R çš„é‚Šç•Œèªªæ˜ ============
            if hasattr(self, 'r_bins') and self.r_bins is not None:
                for i in range(len(self.r_bins)-1):
                    idx = len(self.r_bins) - 2 - i  # åè½‰ç´¢å¼•
                    next_idx = idx + 1
                    export_df[f'R{i+1}_Boundary'] = f"R{i+1}: {self.r_bins[idx]:.0f} to less than {self.r_bins[next_idx]:.0f} days"
                    boundary_columns.append(f'R{i+1}_Boundary')
            
            # ============ F çš„é‚Šç•Œèªªæ˜ï¼ˆä¿®æ”¹å¾Œçš„å›ºå®šåˆ†ç´šï¼‰============
            f_boundary_descriptions = [
                "F1: participated in 1 different work",
                "F2: participated in 2 different works", 
                "F3: participated in 3 different works",
                "F4: participated in 4 or more different works"
            ]
            
            for i, description in enumerate(f_boundary_descriptions):
                export_df[f'F{i+1}_Boundary'] = description
                boundary_columns.append(f'F{i+1}_Boundary')
            
            # ============ M çš„é‚Šç•Œèªªæ˜ ============
            if hasattr(self, 'm_bins') and self.m_bins is not None:
                for i in range(len(self.m_bins)-1):
                    if i == len(self.m_bins)-2:
                        export_df[f'M{i+1}_Boundary'] = f"M{i+1}: ${self.m_bins[i]:.0f} and above"
                    else:
                        next_value = self.m_bins[i+1]
                        export_df[f'M{i+1}_Boundary'] = f"M{i+1}: ${self.m_bins[i]:.0f} to less than ${next_value:.0f}"
                    boundary_columns.append(f'M{i+1}_Boundary')
            
            # ============ T çš„é‚Šç•Œèªªæ˜ ============
            if hasattr(self, 't_bins') and self.t_bins is not None:
                for i in range(len(self.t_bins)-1):
                    if i == len(self.t_bins)-2:
                        export_df[f'T{i+1}_Boundary'] = f"T{i+1}: {int(self.t_bins[i])} times or more in total"
                    else:
                        current_value = int(self.t_bins[i]) + 1 if i > 0 else int(self.t_bins[i])
                        next_value = int(self.t_bins[i+1])
                        export_df[f'T{i+1}_Boundary'] = f"T{i+1}: {current_value} to {next_value} times in total"
                    boundary_columns.append(f'T{i+1}_Boundary')
            
            # ============ A çš„é‚Šç•Œèªªæ˜ ============
            if hasattr(self, 'a_bins') and self.a_bins is not None:
                for i in range(len(self.a_bins)-1):
                    if i == len(self.a_bins)-2:
                        export_df[f'A{i+1}_Boundary'] = f"A{i+1}: ${self.a_bins[i]:.0f} and above per participation"
                    else:
                        next_value = self.a_bins[i+1]
                        export_df[f'A{i+1}_Boundary'] = f"A{i+1}: ${self.a_bins[i]:.0f} to less than ${next_value:.0f} per participation"
                    boundary_columns.append(f'A{i+1}_Boundary')
            
            # çµ„åˆæœ€çµ‚çš„æ¬„ä½é †åº
            columns_to_export = base_columns + sheet_columns + boundary_columns
            
            # ç¢ºä¿æ‰€æœ‰æŒ‡å®šçš„åˆ—éƒ½å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨å‰‡å¡«å……ç‚ºç©º
            for col in columns_to_export:
                if col not in export_df.columns:
                    export_df[col] = ""
            
            return export_df[columns_to_export].copy()
            
        except Exception as e:
            st.error(f"æº–å‚™åŒ¯å‡ºè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return None

# Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»é«”
def main():
    # æª¢æŸ¥èªè­‰
    if not check_authentication():
        return
    
    st.title("ğŸ” RFMTA å®¢æˆ¶åˆ†æå·¥å…· (å®‰å…¨ç‰ˆ)")
    st.markdown("---")
    
    # é¡¯ç¤ºç™»å…¥è³‡è¨Š
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button("ğŸšª ç™»å‡º"):
            st.session_state.authenticated = False
            st.rerun()
    
    # åˆå§‹åŒ–åˆ†æå™¨
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = SecureRFMTAAnalyzer()
    
    # å´é‚Šæ¬„ - è³‡æ–™è¼‰å…¥
    st.sidebar.header("ğŸ”§ è¨­å®š")
    
    # Google Sheets åç¨±è¼¸å…¥
    st.sidebar.subheader("è¼¸å…¥ Google Sheets åç¨±")
    sheet_names_input = st.sidebar.text_area(
        "è«‹è¼¸å…¥å·¥ä½œè¡¨åç¨±ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰",
        height=100,
        placeholder="ä¾‹å¦‚ï¼š\n2024å¹´æ´»å‹•å ±åè¡¨\n2023å¹´æœƒå“¡åå–®"
    )
    
    # è¼‰å…¥è³‡æ–™æŒ‰éˆ•
    if st.sidebar.button("ğŸ”„ è¼‰å…¥è³‡æ–™", type="primary"):
        if sheet_names_input:
            sheet_names = [sanitize_input(name.strip()) for name in sheet_names_input.split('\n') if name.strip()]
            
            with st.spinner("è¼‰å…¥è³‡æ–™ä¸­..."):
                success = st.session_state.analyzer.load_google_sheets_secure(sheet_names)
                if success:
                    st.rerun()
        else:
            st.sidebar.error("è«‹è¼¸å…¥å·¥ä½œè¡¨åç¨±")
    
    # ä¸»è¦å…§å®¹å€åŸŸ
    if st.session_state.analyzer.combined_data is not None:
        # è³‡æ–™æ¦‚è¦½ï¼ˆä¸é¡¯ç¤ºæ•æ„Ÿè³‡è¨Šï¼‰
        st.subheader("ğŸ“‹ è³‡æ–™æ¦‚è¦½")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç¸½è¨˜éŒ„æ•¸", len(st.session_state.analyzer.combined_data))
        
        with col2:
            unique_customers = st.session_state.analyzer.combined_data['Email'].nunique()
            st.metric("å”¯ä¸€å®¢æˆ¶æ•¸", unique_customers)
        
        with col3:
            unique_sheets = st.session_state.analyzer.combined_data['SheetSource'].nunique()
            st.metric("ä½œå“æ•¸é‡", unique_sheets)
        
        # é¡¯ç¤ºä½œå“åƒèˆ‡çµ±è¨ˆ
        if st.checkbox("é¡¯ç¤ºä½œå“åƒèˆ‡çµ±è¨ˆ"):
            sheet_counts = st.session_state.analyzer.combined_data['SheetSource'].value_counts()
            st.write("**å„ä½œå“åƒèˆ‡çµ±è¨ˆ:**")
            for sheet, count in sheet_counts.items():
                st.write(f"- {sheet}: {count} ç­†è¨˜éŒ„")
        
        # åˆ†ææŒ‰éˆ•
        if st.button("ğŸ” åŸ·è¡Œ RFMTA åˆ†æ", type="primary"):
            with st.spinner("åˆ†æä¸­..."):
                success = st.session_state.analyzer.analyze_rfmta()
                if success:
                    st.rerun()
    
    # é¡¯ç¤ºåˆ†æçµæœ
    if st.session_state.analyzer.rfmt_result is not None:
        st.subheader("ğŸ“ˆ RFMTA åˆ†æçµæœ")
        
        # åˆ†æçµæœçµ±è¨ˆ
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**å„æŒ‡æ¨™åˆ†å¸ƒ**")
            for metric in ['R', 'F', 'M', 'T', 'A']:
                dist = st.session_state.analyzer.rfmt_result[metric].value_counts().sort_index()
                st.write(f"{metric}: {dict(dist)}")
        
        with col2:
            st.write("**RFMTA Score ç¯„ä¾‹**")
            sample_scores = st.session_state.analyzer.rfmt_result['RFMTA_Score'].head(5)
            for score in sample_scores.values:
                st.write(f"Score: {score}")
        
        # é¡¯ç¤ºå®Œæ•´çµæœè¡¨æ ¼
        if st.checkbox("é¡¯ç¤ºå®Œæ•´åˆ†æçµæœ"):
            # ä¸é¡¯ç¤ºæ•æ„Ÿçš„ Email å’Œå§“åè³‡è¨Š
            display_columns = ['Recency', 'Frequency', 'Monetary', 'Times', 'Average', 'R', 'F', 'M', 'T', 'A', 'RFMTA_Score']
            available_columns = [col for col in display_columns if col in st.session_state.analyzer.rfmt_result.columns]
            st.dataframe(st.session_state.analyzer.rfmt_result[available_columns])
        
        # å‰µå»º Google Sheet è¼¸å‡º
        st.subheader("ğŸ“Š å‰µå»ºåˆ†æçµæœ Google Sheet")
        
        output_title = st.text_input("è¼¸å‡ºæª”æ¡ˆåç¨±", value="RFMTA_Analysis")
        
        if st.button("ğŸ“ å‰µå»º Google Sheet", type="primary"):
            with st.spinner("æ­£åœ¨å‰µå»º Google Sheet..."):
                export_data = st.session_state.analyzer.get_export_data()
                
                if export_data is not None:
                    sheet_url, sheet_name = st.session_state.analyzer.create_google_sheet_output(
                        export_data, 
                        sanitize_input(output_title)
                    )
                    
                    if sheet_url:
                        st.success("âœ… Google Sheet å‰µå»ºæˆåŠŸï¼")
                        st.markdown(f"**ğŸ“‹ å·¥ä½œè¡¨åç¨±:** {sheet_name}")
                        st.markdown(f"**ğŸ”— [é»æ“Šé€™è£¡é–‹å•Ÿ Google Sheet]({sheet_url})**")
                        
                        # åˆ†äº«æŒ‡å¼•
                        st.info("""
                        **åˆ†äº«èªªæ˜:**
                        - æ­¤ Google Sheet å·²è¨­å®šç‚ºã€Œä»»ä½•æœ‰é€£çµçš„äººéƒ½å¯ä»¥ç·¨è¼¯ã€
                        - æ‚¨å¯ä»¥ç›´æ¥åˆ†äº«ä¸Šæ–¹é€£çµçµ¦åŒäº‹
                        - å¦‚éœ€æ›´æ”¹æ¬Šé™ï¼Œè«‹åœ¨ Google Sheet ä¸­é»æ“Šå³ä¸Šè§’ã€Œåˆ†äº«ã€æŒ‰éˆ•
                        """)
                        
                        # é¡¯ç¤ºåŒ¯å‡ºæ¬„ä½èªªæ˜
                        with st.expander("ğŸ“‹ åŒ¯å‡ºæ¬„ä½èªªæ˜"):
                            st.markdown("""
                            **åŸºæœ¬æ¬„ä½:**
                            - Email, å§“å, Recency, Frequency, Monetary, Times, Average
                            - R, F, M, T, A, RFMTA_Score
                            
                            **ä½œå“åƒèˆ‡æ¬¡æ•¸:**
                            - å„ä½œå“çš„å€‹åˆ¥åƒèˆ‡æ¬¡æ•¸çµ±è¨ˆ
                            
                            **é‚Šç•Œèªªæ˜:**
                            - R1-R4_Boundary: æœ€è¿‘è³¼è²·æ™‚é–“åˆ†ç´šèªªæ˜
                            - F1-F4_Boundary: åƒèˆ‡ä½œå“æ•¸åˆ†ç´šèªªæ˜ï¼ˆå›ºå®šåˆ†ç´šï¼‰
                            - M1-M4_Boundary: æ¶ˆè²»é‡‘é¡åˆ†ç´šèªªæ˜
                            - T1-T4_Boundary: ç¸½åƒèˆ‡æ¬¡æ•¸åˆ†ç´šèªªæ˜
                            - A1-A4_Boundary: å¹³å‡æ¶ˆè²»åˆ†ç´šèªªæ˜
                            
                            **F åˆ†ç´šç‰¹è‰²ï¼ˆå·²ä¿®æ”¹ç‚ºå›ºå®šåˆ†ç´šï¼‰:**
                            - F1: åƒåŠ  1 å€‹ä½œå“
                            - F2: åƒåŠ  2 å€‹ä½œå“
                            - F3: åƒåŠ  3 å€‹ä½œå“
                            - F4: åƒåŠ  4 å€‹æˆ–ä»¥ä¸Šä½œå“
                            """)
    
    else:
        if st.session_state.analyzer.combined_data is None:
            st.info("ğŸ‘† è«‹å…ˆåœ¨å·¦å´è¼‰å…¥è³‡æ–™")
            
            # ä½¿ç”¨èªªæ˜
            st.subheader("ğŸ“– ä½¿ç”¨èªªæ˜")
            st.markdown("""
            **å®‰å…¨ç‰ˆæœ¬ç‰¹è‰²:**
            - ğŸ” éœ€è¦å¯†ç¢¼èªè­‰æ‰èƒ½ä½¿ç”¨
            - ğŸ”’ ä½¿ç”¨é è¨­çš„ Google API æ†‘è­‰ï¼Œç„¡éœ€ä¸Šå‚³æ•æ„Ÿæª”æ¡ˆ
            - ğŸ—‘ï¸ åˆ†æå®Œæˆå¾Œè‡ªå‹•æ¸…é™¤åŸå§‹è³‡æ–™
            - â±ï¸ Session æœƒåœ¨ 1 å°æ™‚å¾Œè‡ªå‹•éæœŸ
            - ğŸ“Š çµæœç›´æ¥è¼¸å‡ºç‚º Google Sheetï¼Œæ˜“æ–¼åˆ†äº«
            
            **ä½¿ç”¨æ­¥é©Ÿ:**
            1. åœ¨å·¦å´è¼¸å…¥è¦åˆ†æçš„ Google Sheets åç¨±
            2. é»æ“Šã€Œè¼‰å…¥è³‡æ–™ã€
            3. åŸ·è¡Œ RFMTA åˆ†æ
            4. å‰µå»ºçµæœ Google Sheet ä¸¦åˆ†äº«
            
            **RFMTA åˆ†æèªªæ˜:**
            - **R (Recency)**: æœ€è¿‘è³¼è²·æ™‚é–“ï¼ˆå››åˆ†ä½æ•¸åˆ†ç´šï¼‰
            - **F (Frequency)**: è·¨ä½œå“åƒèˆ‡æ¬¡æ•¸ï¼ˆå›ºå®šåˆ†ç´šï¼š1,2,3,4+å€‹ä½œå“ï¼‰
            - **M (Monetary)**: ç¸½æ¶ˆè²»é‡‘é¡ï¼ˆå››åˆ†ä½æ•¸åˆ†ç´šï¼‰
            - **T (Times)**: ç¸½åƒèˆ‡æ¬¡æ•¸ï¼ˆå››åˆ†ä½æ•¸åˆ†ç´šï¼‰
            - **A (Average)**: å¹³å‡æ¯æ¬¡æ¶ˆè²»é‡‘é¡ï¼ˆå››åˆ†ä½æ•¸åˆ†ç´šï¼‰
            """)

if __name__ == "__main__":
    main()
